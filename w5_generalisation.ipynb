{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### MLAI Week 5: Generalisation\n",
    "\n",
    "### Neil D. Lawrence\n",
    "\n",
    "### 27th October 2015"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Review\n",
    "- Last time: introduced basis functions.\n",
    "- Showed how to maximize the likelihood of a non-linear model that's linear in parameters.\n",
    "- Explored hte different characteristics of different basis function models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Polynomial Fits to Olymics Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import pods\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import mlai\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 2, figsize=(14,7))\n",
    "\n",
    "basis = mlai.polynomial\n",
    "\n",
    "data = pods.datasets.olympic_marathon_men()\n",
    "x = data['X']\n",
    "y = data['Y']\n",
    "num_data = x.shape[0]\n",
    "\n",
    "data_limits = [1892, 2020]\n",
    "max_basis = y.shape[0]\n",
    "\n",
    "ll = np.array([np.nan]*(max_basis))\n",
    "sum_squares = np.array([np.nan]*(max_basis))\n",
    "\n",
    "for num_basis in range(1,max_basis+1):\n",
    "    \n",
    "    model= mlai.LM(x, y, basis, num_basis=num_basis, data_limits=data_limits)\n",
    "    model.fit()\n",
    "    sum_squares[num_basis-1] = model.objective()/num_data \n",
    "    ll[num_basis-1] = model.log_likelihood()\n",
    "    mlai.plot_marathon_fit(model=model, data_limits=data_limits, \n",
    "                           objective=sum_squares, objective_ylim=[0, 0.3],\n",
    "                           fig=f, ax=ax)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](./diagrams/olympic_polynomial1.svg) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](./diagrams/olympic_polynomial2.svg) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](./diagrams/olympic_polynomial2.svg) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](./diagrams/olympic_polynomial3.svg) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](./diagrams/olympic_polynomial4.svg) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](./diagrams/olympic_polynomial5.svg) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](./diagrams/olympic_polynomial6.svg) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](./diagrams/olympic_polynomial7.svg) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](./diagrams/olympic_polynomial8.svg) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](./diagrams/olympic_polynomial9.svg) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](./diagrams/olympic_polynomial10.svg) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](./diagrams/olympic_polynomial11.svg) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](./diagrams/olympic_polynomial12.svg) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](./diagrams/olympic_polynomial27.svg) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Overfitting\n",
    "- Increase number of basis functions we obtain a better 'fit' to the data.\n",
    "- How will the model perform on previously unseen data?\n",
    "- Let's consider predicting the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 2, figsize=(14,7))\n",
    "\n",
    "val_start = 20;\n",
    "x = data['X'][:val_start, :]\n",
    "x_val = data['X'][val_start:, :]\n",
    "y = data['Y'][:val_start, :]\n",
    "y_val = data['Y'][val_start:, :]\n",
    "num_val_data = x_val.shape[0]\n",
    " \n",
    "    \n",
    "max_basis = 7\n",
    "\n",
    "ll = np.array([np.nan]*(max_basis))\n",
    "ss = np.array([np.nan]*(max_basis))\n",
    "ss_val = np.array([np.nan]*(max_basis))\n",
    "for num_basis in range(1,max_basis+1):\n",
    "    \n",
    "    model= mlai.LM(x, y, basis, num_basis=num_basis, data_limits=data_limits)\n",
    "    model.fit()\n",
    "    ss[num_basis-1] = model.objective()\n",
    "    f_val = model.predict(x_val)\n",
    "    ss_val[num_basis-1] = ((y_val-f_val)**2).mean() \n",
    "    ll[num_basis-1] = model.log_likelihood()\n",
    "    mlai.plot_marathon_fit(model=model, data_limits=data_limits, \n",
    "                           objective=np.sqrt(ss_val), objective_ylim=[0,0.6],\n",
    "                           fig=f, ax=ax, prefix='olympic_val',\n",
    "                           x_val=x_val, y_val=y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](./diagrams/olympic_val_polynomial1.svg) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](./diagrams/olympic_val_polynomial2.svg) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](./diagrams/olympic_val_polynomial3.svg) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](./diagrams/olympic_val_polynomial4.svg) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](./diagrams/olympic_val_polynomial5.svg) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](./diagrams/olympic_val_polynomial6.svg) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](./diagrams/olympic_val_polynomial7.svg) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Extrapolation\n",
    "\n",
    "- Here we are training beyond where the model has learnt.\n",
    "- This is known as *extrapolation*.\n",
    "- Extrapolation is predicting into the future here, but could be:\n",
    "    - Predicting back to the unseen past (pre 1892)\n",
    "    - Spatial prediction (e.g. Cholera rates outside Manchester given rates inside Manchester)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Alan Turing\n",
    "- He was a formidable Marathon runner. \n",
    "- In 1946 he ran a time 2 hours 46 minutes.\n",
    "- What is the probability he would have won an Olympics if one had been held in 1946?  \n",
    "![Alan Turing running in 1946](http://www.turing.org.uk/turing/pi2/run.jpg)\n",
    "<center>*Alan Turing, in 1946 he was only 11 minutes slower than the winner of the 1948 games. Would he have won a hypothetical games held in 1946? Source: [Alan Turing Internet Scrapbook](http://www.turing.org.uk/scrapbook/run.html).*</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Interpolation\n",
    "- Predicting the wining time for 1946 Olympics is *interpolation*.\n",
    "- This is because we have times from 1936 and 1948.\n",
    "- If we want a model for *interpolation* how can we test it?\n",
    "- One trick is to sample the validation set from throughout the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 2, figsize=(14,7))\n",
    "\n",
    "val_start = 20;\n",
    "\n",
    "perm = np.random.permutation(data['X'].shape[0])\n",
    "x = data['X'][perm[:val_start], :]\n",
    "x_val = data['X'][perm[val_start:], :]\n",
    "y = data['Y'][perm[:val_start], :]\n",
    "y_val = data['Y'][perm[val_start:], :]\n",
    "num_val_data = x_val.shape[0]\n",
    " \n",
    "    \n",
    "max_basis = 7\n",
    "\n",
    "ll = np.array([np.nan]*(max_basis))\n",
    "ss = np.array([np.nan]*(max_basis))\n",
    "ss_val = np.array([np.nan]*(max_basis))\n",
    "for num_basis in range(1,max_basis+1):\n",
    "    \n",
    "    model= mlai.LM(x, y, basis, num_basis=num_basis, data_limits=data_limits)\n",
    "    model.fit()\n",
    "    ss[num_basis-1] = model.objective()\n",
    "    f_val = model.predict(x_val)\n",
    "    ss_val[num_basis-1] = ((y_val-f_val)**2).mean() \n",
    "    ll[num_basis-1] = model.log_likelihood()\n",
    "    mlai.plot_marathon_fit(model=model, data_limits=data_limits, \n",
    "                           objective=np.sqrt(ss_val), objective_ylim=[0.2,0.6],\n",
    "                           fig=f, ax=ax, prefix='olympic_val_inter',\n",
    "                           x_val=x_val, y_val=y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](./diagrams/olympic_val_inter_polynomial1.svg) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](./diagrams/olympic_val_inter_polynomial2.svg) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](./diagrams/olympic_val_inter_polynomial3.svg) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](./diagrams/olympic_val_inter_polynomial4.svg) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](./diagrams/olympic_val_inter_polynomial7.svg) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](./diagrams/olympic_val_inter_polynomial5.svg) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](./diagrams/olympic_val_inter_polynomial7.svg) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](./diagrams/olympic_val_inter_polynomial6.svg) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](./diagrams/olympic_val_inter_polynomial7.svg) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Choice of Validation Set\n",
    "\n",
    "- The choice of validation set should reflect how you will use the model in practice.\n",
    "- For extrapolation into the future we tried validating with data from the future.\n",
    "- For interpolation we chose validation set from data.\n",
    "- For different validation sets we could get different results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Leave One Out Error\n",
    "- Take training set and remove one point.\n",
    "- Train on the remaining data.\n",
    "- Compute the error on the point you removed (which wasn't in the training data).\n",
    "- Do this for each point in the training set in turn.\n",
    "- Average the resulting error. \n",
    "- This is the leave one out error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 2, figsize=(14,7))\n",
    "\n",
    "num_data = data['X'].shape[0]\n",
    "num_parts = num_data\n",
    "partitions = []\n",
    "for part in range(num_parts):\n",
    "    train_ind = list(range(part))\n",
    "    train_ind.extend(range(part+1,num_data))\n",
    "    val_ind = [part]\n",
    "    partitions.append((train_ind, val_ind))\n",
    "\n",
    "    max_basis = 7\n",
    "\n",
    "    ll = np.array([np.nan]*(max_basis))\n",
    "    ss = np.array([np.nan]*(max_basis))\n",
    "    ss_val = np.array([np.nan]*(max_basis))\n",
    "    for num_basis in range(1,max_basis+1):\n",
    "        ss_val_temp = 0.\n",
    "        for part, (train_ind, val_ind) in enumerate(partitions):\n",
    "            x = data['X'][train_ind, :]\n",
    "            x_val = data['X'][val_ind, :]\n",
    "            y = data['Y'][train_ind, :]\n",
    "            y_val = data['Y'][val_ind, :]\n",
    "            num_val_data = x_val.shape[0]\n",
    "\n",
    "            model= mlai.LM(x, y, basis, num_basis=num_basis, data_limits=data_limits)\n",
    "            model.fit()\n",
    "            ss[num_basis-1] = model.objective()\n",
    "            f_val = model.predict(x_val)\n",
    "            ss_val_temp += ((y_val-f_val)**2).mean() \n",
    "            mlai.plot_marathon_fit(model=model, data_limits=data_limits, \n",
    "                                objective=np.sqrt(ss_val), objective_ylim=[0.2,0.6],\n",
    "                                   fig=f, ax=ax, prefix='olympic_loo' + str(part) + '_inter',\n",
    "                                   x_val=x_val, y_val=y_val)\n",
    "        ss_val[num_basis-1] = ss_val_temp/(num_parts)\n",
    "        mlai.plot_marathon_fit(model=model, data_limits=data_limits, \n",
    "                                objective=np.sqrt(ss_val), objective_ylim=[0.2,0.6],\n",
    "                                   fig=f, ax=ax, prefix='olympic_loo_inter',\n",
    "                                   x_val=x_val, y_val=y_val)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./diagrams/olympic_loo_inter_polynomial7.svg) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bias Variance Decomposition\n",
    "\n",
    "Expected test error for different variations of the *training data* sampled from, $\\Pr(\\mathbf{x}, y)$\n",
    "\n",
    "$$E\\left[ (y - f^*(\\mathbf{x}))^2 \\right]$$\n",
    "\n",
    "Decompose as\n",
    "\n",
    "$$E\\left[ (y - f(\\mathbf{x}))^2 \\right] = \\text{bias}\\left[f^*(\\mathbf{x})\\right]^2 + \\text{variance}\\left[f^*(\\mathbf{x})\\right] +\\sigma^2$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bias\n",
    "\n",
    "- Given by\n",
    "    $$\\text{bias}\\left[f^*(\\mathbf{x})\\right] = E\\left[f^*(\\mathbf{x})\\right] - f(\\mathbf{x})$$\n",
    "    \n",
    "- Error due to bias comes from a model that's too simple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Variance\n",
    "\n",
    "- Given by\n",
    "    $$\\text{variance}\\left[f^*(\\mathbf{x})\\right] = E\\left[\\left(f^*(\\mathbf{x}) -  E\\left[f^*(\\mathbf{x})\\right]\\right)^2\\right]$$\n",
    "    \n",
    "- Slight variations in the training set cause changes in the prediction. Error due to variance is error in the model due to an overly complex model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### $k$ Fold Cross Validation\n",
    "\n",
    "- Leave one out error can be very time consuming.\n",
    "- Need to train your algorithm $n$ times.\n",
    "- An alternative: $k$ fild cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 2, figsize=(14,7))\n",
    "\n",
    "num_data = data['X'].shape[0]\n",
    "num_parts = 5\n",
    "partitions = []\n",
    "ind = list(np.random.permutation(num_data))\n",
    "start = 0\n",
    "for part in range(num_parts):\n",
    "    end = round((float(num_data)/num_parts)*part)\n",
    "    train_ind = ind[:start]\n",
    "    train_ind.extend(ind[end:])\n",
    "    val_ind = ind[start:end]\n",
    "    partitions.append((train_ind, val_ind))\n",
    "    start = end\n",
    "\n",
    "    \n",
    "max_basis = 7\n",
    "\n",
    "ll = np.array([np.nan]*(max_basis))\n",
    "ss = np.array([np.nan]*(max_basis))\n",
    "ss_val = np.array([np.nan]*(max_basis))\n",
    "for num_basis in range(1,max_basis+1):\n",
    "    ss_val_temp = 0.\n",
    "    for part, (train_ind, val_ind) in enumerate(partitions):\n",
    "        x = data['X'][train_ind, :]\n",
    "        x_val = data['X'][val_ind, :]\n",
    "        y = data['Y'][train_ind, :]\n",
    "        y_val = data['Y'][val_ind, :]\n",
    "        num_val_data = x_val.shape[0]\n",
    "\n",
    "        model= mlai.LM(x, y, basis, num_basis=num_basis, data_limits=data_limits)\n",
    "        model.fit()\n",
    "        ss[num_basis-1] = model.objective()\n",
    "        f_val = model.predict(x_val)\n",
    "        ss_val_temp += ((y_val-f_val)**2).mean() \n",
    "        mlai.plot_marathon_fit(model=model, data_limits=data_limits, \n",
    "                            objective=np.sqrt(ss_val), objective_ylim=[0.2,0.6],\n",
    "                               fig=f, ax=ax, prefix='olympic_' + str(num_parts) + 'cv' + str(part) + '_inter',\n",
    "                               x_val=x_val, y_val=y_val)\n",
    "    ss_val[num_basis-1] = ss_val_temp/(num_parts)\n",
    "    mlai.plot_marathon_fit(model=model, data_limits=data_limits, \n",
    "                            objective=np.sqrt(ss_val), objective_ylim=[0.2,0.6],\n",
    "                               fig=f, ax=ax, prefix='olympic_' + str(num_parts) + 'cv_inter',\n",
    "                               x_val=x_val, y_val=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./diagrams/olympic_5cv_inter_polynomial7.svg) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Reading\n",
    "- Section 1.5 of @Rogers:book11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ss_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ss_val_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "((y_val-f_val)**2).mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
